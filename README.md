# Text-to-SQL Agent

¬°Hola! üëã 

Esta es la soluci√≥n para la prueba t√©cnica. Te voy a explicar qu√© hace, c√≥mo lo constru√≠ y c√≥mo puedes correrlo t√∫ mismo.

## ¬øQu√© hace este proyecto?

Es un agente conversacional que convierte preguntas en lenguaje natural (como "¬øCu√°l fue el precio promedio de venta en Chile?") en consultas SQL y las ejecuta. Lo interesante es que puede responder de dos formas:

1. **Usando contexto**: Si la pregunta puede responderse con la informaci√≥n general que proporcionas sobre tu empresa, lo hace directamente sin tocar la base de datos.
2. **Consultando la base de datos**: Si necesita datos espec√≠ficos, genera una consulta SQL autom√°ticamente, la ejecuta e interpreta los resultados para darte una respuesta en lenguaje natural.

Todo esto usando modelos de IA de AWS Bedrock: Claude y Llama a trav√©s de LangChain.

## ¬øC√≥mo lo hice? (Arquitectura)

Decid√≠ usar un **modelo directo y simplificado**. La raz√≥n es que quer√≠a algo que funcionara r√°pido sin complicaciones, simplemente LangChain conect√°ndose directamente a AWS Bedrock y mostrando el resultado en gradio.

**¬øPor qu√© esta arquitectura?**
- Es m√°s simple de entender y mantener
- Menos latencia (comunicaci√≥n directa con Bedrock)
- Configuraci√≥n r√°pida sin necesidad de servidores adicionales
- Perfecta para prototipos y pruebas

Si quieres m√°s detalles t√©cnicos, los dejo m√°s abajo en la secci√≥n de Arquitectura.

## Estructura del proyecto
Si quieres entender c√≥mo est√° organizado el c√≥digo, aqu√≠ te explico:

### Archivos:

- **`src/main.py`**: El cerebro del agente. Aqu√≠ est√°:
  - La carga de los modelos LLM desde Bedrock
  - La l√≥gica que decide si usar contexto o SQL
  - La generaci√≥n de SQL desde lenguaje natural
  - La interpretaci√≥n de resultados
  - El orquestador que coordina todo el flujo

- **`src/database.py`**: Todo lo relacionado con bases de datos:
  - Conectarse a SQLite
  - Extraer el esquema de las tablas
  - Formatear el esquema para los prompts
  - Ejecutar queries

- **`src/api.py`**: La API REST con FastAPI. Incluye endpoints para hacer queries.

- **`src/ui.py`**: La interfaz web de Gradio. Aqu√≠ est√° toda la UI de la aplicaci√≥n.

### Directorio `data/`

- **`seed_data.sql`**: El script SQL con el esquema y datos de ejemplo
- **`demo.db`**: La base de datos que se creada.

## Lo que necesitas antes de empezar

- Python 3.10 o superior (puedes verificar tu versi√≥n con `python --version`)
- Las credenciales de AWS que te envi√© por correo (Access Key y Secret Access Key)

> **Nota r√°pida sobre las credenciales**: S√© que pasar credenciales por correo no es la pr√°ctica m√°s segura del mundo, pero para esta prueba lo hice as√≠ para que puedas empezar a probar inmediatamente sin tener que configurar IAM roles o perfiles de AWS. En producci√≥n usar√≠a variables de entorno o IAM roles. ¬°Pero para probar esto funciona perfecto :D !

## C√≥mo correr el proyecto

Te explico c√≥mo lo pongo en marcha. Es bastante simple:

### 1. Navega a la carpeta del proyecto  luego de clonar el repositorio

```bash
cd Text-to-SQL-Agent
```

### 2. Crea un entorno virtual

```bash
# En macOS/Linux
python3 -m venv venv

# En Windows
python -m venv venv
```

### 3. Activa el entorno virtual

```bash
# En macOS/Linux
source venv/bin/activate

# En Windows
venv\Scripts\activate
```

Ver√°s `(venv)` aparecer en tu terminal - eso significa que est√° activo ‚úÖ

### 4. Instala las dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

Esto instalar√° todas las librer√≠as que necesita el proyecto (LangChain, Gradio, FastAPI, boto3, etc.)

### 5. ¬°Ejecuta la aplicaci√≥n!

```bash
python main.py
```

Se abrir√° autom√°ticamente en tu navegador en `http://localhost:7860`. Si no se abre solo, copia esa URL y p√©galo en tu navegador.

### 7. Ingresa las credenciales AWS

Cuando la aplicaci√≥n est√© corriendo, ver√°s campos para ingresar las credenciales que te envi√© por correo. Simplemente c√≥pialas y p√©galas ah√≠.

> üí° **Tip**: Las credenciales solo se usan durante la sesi√≥n y no se guardan permanentemente. Si cierras la aplicaci√≥n, tendr√°s que ingresarlas de nuevo y solo tienen una duraci√≥n de 48 horas.

---

**Cuando termines de probar:**

Para desactivar el entorno virtual simplemente escribe:

```bash
deactivate
```

## C√≥mo usar la interfaz

Una vez que la aplicaci√≥n est√© corriendo, la interfaz es s√∫per intuitiva. Te explico qu√© hace cada cosa:

1. **Base de datos**: Por defecto usa la demo que creamos (`data/demo.db`), pero puedes cargar tu propia base SQLite si quieres.

2. **Contexto de la empresa**: Este es el "conocimiento general" que le das al agente. Por ejemplo, si escribes "Mi empresa vende productos electr√≥nicos y tiene 5000 ventas mensuales", el agente puede responder preguntas sobre esto sin tocar la base de datos.

3. **Modelo LLM**: Puedes elegir entre Claude 3 Sonnet, Claude 3 Haiku o Llama 3 70B. Recomiendo empezar con "Claude 3 Haiku" porque es r√°pido y eficiente.

4. **Credenciales AWS**: Aqu√≠ pegas las credenciales que te envi√© por correo.

5. **Haz tu pregunta**: Escribe lo que quieras saber en lenguaje natural, como si le hablaras a un compa√±ero.

6. **Click en "Enviar"** y espera la magia ‚ú®

### Ejemplos de preguntas que puedes hacer

**Pregunta que usa contexto:**
- T√∫: "¬øCu√°ntos productos principales vende TechNova?"
- El agente: Detecta que puede responder con el contexto y te dice directamente: "TechNova se enfoca en tres categor√≠as principales: smartphones, notebooks y accesorios."

**Pregunta que consulta la base de datos:**
- T√∫: "¬øCu√°l fue el precio promedio de venta en Chile?"
- El agente: 
  - Genera este SQL: `SELECT AVG(precio) FROM ventas WHERE pais = 'Chile';`
  - Lo ejecuta en la base de datos
  - Te responde: "El precio promedio de venta en Chile fue de 1800 USD."

**M√°s ideas para probar:**
- "¬øCu√°ntas ventas de smartphones hubo en mayo?"
- "¬øQu√© pa√≠ses tienen ventas registradas?"
- "¬øCu√°l es el producto m√°s caro vendido?"
- "Mu√©strame las ventas de notebooks en Argentina"

### Tambi√©n hay una API REST (opcional)

Si prefieres consumir el agente como API en lugar de usar la interfaz web, tambi√©n inclu√≠ una API REST con FastAPI. Para correrla:

```bash
uvicorn src.api:app --reload --port 8000
```

Estar√° disponible en `http://localhost:8000`.

**Endpoints que puedes usar:**

- `POST /query`: Para hacer preguntas
  ```json
  {
    "use_default_db": true,
    "db_path": "data/demo.db",
    "context": "La empresa TechNova vende productos electr√≥nicos...",
    "model_name": "Claude 3 Haiku",
    "question": "¬øCu√°l es el promedio de ventas?"
  }
  ```

- `GET /health`: Para verificar que el servicio est√© funcionando

## Modelos Disponibles

- **Claude 3 Sonnet**: Modelo balanceado de Anthropic
- **Claude 3 Haiku**: Modelo r√°pido y eficiente de Anthropic
- **Llama 3 70B**: Modelo de Meta, optimizado para instrucciones

## Detalles t√©cnicos (si te interesa c√≥mo lo constru√≠)

### Arquitectura: Modelo Directo y Simplificado

Como te coment√© arriba, eleg√≠ una arquitectura directa sin complicaciones. Aqu√≠ te explico los detalles:

**Componentes principales:**
- **Conexi√≥n directa**: LangChain habla directamente con AWS Bedrock, sin servidores intermedios ni MCP
- **Chain Pattern**: Uso las "cadenas" de LangChain para orquestar el flujo
- **Separaci√≥n de responsabilidades**: Cada m√≥dulo hace una cosa bien (UI, API, l√≥gica, base de datos)

### ¬øC√≥mo funciona internamente?

El agente toma decisiones en dos pasos:

**Paso 1: ¬øPuedo responder con contexto?**
- Analiza tu pregunta y el contexto que proporcionaste
- Si encuentra la respuesta ah√≠, te responde directamente (r√°pido y eficiente)

**Paso 2: Necesito consultar la base de datos**
Si no puede responder con contexto:
1. Extrae el esquema de tu base de datos
2. Le pide al LLM que genere una consulta SQL v√°lida bas√°ndose en tu pregunta
3. Ejecuta esa consulta en la base de datos
4. Interpreta los resultados y te da una respuesta en lenguaje natural

### ¬øPor qu√© esta arquitectura?

- ‚úÖ **Simple**: No necesitas entender MCP ni configurar servidores extra
- ‚úÖ **R√°pida**: Menos latencia = respuestas m√°s inmediatas
- ‚úÖ **F√°cil de mantener**: El c√≥digo es claro y directo
- ‚úÖ **Perfecta para prototipos**: Funciona r√°pido sin mucha configuraci√≥n

## Base de Datos

La base de datos demo incluye una tabla `ventas` con los siguientes campos:
- `id`: Identificador √∫nico
- `producto`: Nombre del producto
- `categoria`: Categor√≠a del producto (smartphones, notebooks, accesorios)
- `precio`: Precio de venta
- `pais`: Pa√≠s donde se realiz√≥ la venta
- `fecha_venta`: Fecha de la venta

Puedes extender o modificar `data/seed_data.sql` para agregar m√°s datos de prueba.

## Si algo sale mal (troubleshooting)

**"Modelo no soportado"**
- Aseg√∫rate de que el nombre del modelo coincida exactamente con las opciones del dropdown (Claude 3 Sonnet, Claude 3 Haiku, etc.)

**Error de credenciales AWS**
- Revisa que hayas copiado bien las credenciales (a veces hay espacios extras)
- Verifica que las credenciales que te envi√© sigan siendo v√°lidas

**AccessDeniedException**
- Esto significa que las credenciales no tienen permisos para usar Bedrock. Si pasa esto, av√≠same y reviso los permisos en AWS.

**Base de datos no encontrada**
- Ejecuta de nuevo: `python create_demo_db.py`

**Error de conexi√≥n a la base de datos**
- Verifica que el archivo `data/demo.db` exista
- Si cargaste tu propia base de datos, aseg√∫rate de que sea un archivo SQLite v√°lido

## Stack tecnol√≥gico que us√©

Para que sepas qu√© tecnolog√≠as eleg√≠ y por qu√©:

- **Python 3.10+**: Base del proyecto
- **LangChain**: Framework que hace s√∫per f√°cil trabajar con LLMs y crear cadenas de procesamiento
- **AWS Bedrock**: Servicio de AWS para acceder a modelos como Claude y Llama
- **Gradio**: Para crear la interfaz web r√°pidamente (muy f√°cil de usar)
- **FastAPI**: Para la API REST (r√°pida y moderna)
- **SQLite**: Base de datos simple y perfecta para este tipo de demos
- **boto3**: SDK oficial de AWS para Python

---

## √öltimas palabras

Este proyecto lo hice con mucho cari√±o para demostrar c√≥mo puedo trabajar con LLMs, AWS y crear herramientas √∫tiles. Si tienes preguntas o quieres que explique algo m√°s a fondo, ¬°no dudes en preguntar! 

¬°Espero que te sea √∫til y puedas probarlo sin problemas! üöÄ

